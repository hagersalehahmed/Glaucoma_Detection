{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms as T, models\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    cohen_kappa_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(data_dir):\n",
    "    \"\"\"Get class names from dataset directory.\"\"\"\n",
    "    all_data = datasets.ImageFolder(data_dir)\n",
    "    return all_data.classes\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size, train=False):\n",
    "    \"\"\"Prepare data loaders for training, validation, and testing.\"\"\"\n",
    "    if train:\n",
    "        # Data augmentation for training\n",
    "        transform = T.Compose([\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomVerticalFlip(),\n",
    "            \n",
    "            T.Resize((299, 299)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        train_data = datasets.ImageFolder(os.path.join(data_dir, \"train/\"), transform=transform)\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        return train_loader, len(train_data)\n",
    "    else:\n",
    "        # Validation and test data transformations\n",
    "        transform = T.Compose([\n",
    "            T.Resize((299, 299)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        val_data = datasets.ImageFolder(os.path.join(data_dir, \"validation/\"), transform=transform)\n",
    "        test_data = datasets.ImageFolder(os.path.join(data_dir, \"test/\"), transform=transform)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        return val_loader, test_loader, len(val_data), len(test_data)\n",
    "\n",
    "# Dataset paths and loaders\n",
    "dataset_path = \"new_directories\"\n",
    "batch_size = 32  # Update batch size for efficiency\n",
    "\n",
    "(train_loader, train_data_len) = get_data_loaders(dataset_path, batch_size, train=True)\n",
    "(val_loader, test_loader, valid_data_len, test_data_len) = get_data_loaders(dataset_path, batch_size, train=False)\n",
    "\n",
    "classes = get_classes(\"new_directories/train\")\n",
    "num_classes = len(classes)\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "dataset_sizes = {\"train\": train_data_len, \"val\": valid_data_len}\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the pre-trained Inception-v3 model\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Update the fully connected layer for the number of classes\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)\n",
    "\n",
    "# Print model structure for confirmation\n",
    "print(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    \"\"\"Train and validate the model.\"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluation mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "                    # Handle auxiliary logits for Inception-v3\n",
    "                    if isinstance(outputs, tuple) or hasattr(outputs, \"logits\"):\n",
    "                        main_outputs = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n",
    "                        aux_outputs = outputs.aux_logits if hasattr(outputs, \"aux_logits\") else None\n",
    "                        loss = criterion(main_outputs, labels)\n",
    "                        if aux_outputs is not None:  # Add auxiliary loss if present\n",
    "                            loss += 0.4 * criterion(aux_outputs, labels)\n",
    "                    else:\n",
    "                        main_outputs = outputs\n",
    "                        loss = criterion(main_outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(main_outputs, 1)  # Extract predictions from logits\n",
    "\n",
    "                    # Backward pass and optimization in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # Step the scheduler in the training phase\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_true = []\n",
    "y_proba = []\n",
    "y_pred = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader):\n",
    "        # Forward pass\n",
    "        output = model(x.to(device))\n",
    "        \n",
    "        # Store true labels\n",
    "        y_true.extend(y.numpy())\n",
    "        \n",
    "        # Get predicted probabilities (softmax output)\n",
    "        probabilities = torch.softmax(output, dim=1)  # Assuming it's a multi-class classification\n",
    "        y_proba.extend(probabilities.cpu().numpy())  # Store probabilities\n",
    "        \n",
    "        # Get predicted classes (argmax for final class prediction)\n",
    "        pred = torch.argmax(probabilities, axis=1).cpu().numpy()\n",
    "        y_pred.extend(pred)\n",
    "\n",
    "# Convert to numpy arrays for further processing\n",
    "y_true = np.array(y_true)\n",
    "y_proba = np.array(y_proba)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# If binary classification, take probabilities of the positive class\n",
    "if y_proba.shape[1] == 2:  # For binary classification\n",
    "    y_proba = y_proba[:, 1]  # Take probabilities for the positive class\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "\n",
    "# Plot the confusion matrix without percentages\n",
    "disp.plot(cmap=\"Blues\", values_format='')\n",
    "plt.title(\"EfficientNetB0\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=classes, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import f1_score, roc_auc_score, cohen_kappa_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "import pandas as pd \n",
    "\n",
    "finaltrain = pd.DataFrame([])\n",
    "\n",
    "finaltrain = finaltrain._append({\n",
    "                                        'Accuracy' : round(accuracy_score(y_true, y_pred)*100,3),\n",
    "                                        'PrecisionTrain':round(precision_score(y_true, y_pred, average = 'weighted')*100,3),\n",
    "                                        'RecallTrain':round(recall_score(y_true, y_pred, average = 'weighted')*100,3)  ,\n",
    "                                        'F1Train':round(f1_score(y_true, y_pred, average = 'weighted')*100,3)}\n",
    "                                      \n",
    "                                        , ignore_index=True)\n",
    "finaltrain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Move ResNet to device (GPU or CPU)\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "# ===============================\n",
    "# 2. Function to Extract Features from Any Layer\n",
    "# ===============================\n",
    "# Dictionary to store features\n",
    "features = {}\n",
    "\n",
    "# Hook function to capture the output from any layer\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Function to register the hook based on layer name\n",
    "def register_layer_hook(model, layer_name):\n",
    "    # Use eval() to access the layer dynamically\n",
    "    layer = eval(f'model.{layer_name}')\n",
    "    layer.register_forward_hook(get_features(layer_name))\n",
    "\n",
    "# ===============================\n",
    "# 3. Extract Features from ResNet's Specified Layer\n",
    "# ===============================\n",
    "# Assume train_loader and test_loader are defined DataLoader objects for your dataset\n",
    "\n",
    "def extract_features(layer_name, train_loader, test_loader, model, device):\n",
    "    # Register hook for the provided layer name\n",
    "    register_layer_hook(model, layer_name)\n",
    "    \n",
    "    train_features_list = []  # To store features for training data\n",
    "    train_labels_list = []  # To store labels for training data\n",
    "    test_features_list = []  # To store features for test data\n",
    "    test_labels_list = []  # To store labels for test data\n",
    "\n",
    "    # Extract features from training dataset\n",
    "    for images, labels in train_loader:\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            _ = model(images)\n",
    "            \n",
    "            # Extract layer features\n",
    "            layer_features = features[layer_name]\n",
    "            \n",
    "            # Flatten features if needed (depends on the shape of your features)\n",
    "            layer_features = layer_features.view(layer_features.size(0), -1)\n",
    "            \n",
    "            train_features_list.append(layer_features)\n",
    "            train_labels_list.append(labels)\n",
    "\n",
    "    # Extract features from test dataset\n",
    "    for images, labels in test_loader:\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            _ = model(images)\n",
    "            \n",
    "            # Extract layer features\n",
    "            layer_features = features[layer_name]\n",
    "            \n",
    "            # Flatten features if needed\n",
    "            layer_features = layer_features.view(layer_features.size(0), -1)\n",
    "            \n",
    "            test_features_list.append(layer_features)\n",
    "            test_labels_list.append(labels)\n",
    "\n",
    "    # Concatenate features and labels from the list to create tensors\n",
    "    train_features = torch.cat(train_features_list)\n",
    "    train_labels = torch.cat(train_labels_list)\n",
    "    test_features = torch.cat(test_features_list)\n",
    "    test_labels = torch.cat(test_labels_list)\n",
    "\n",
    "    # ===============================\n",
    "    # 4. Save Features to Files\n",
    "    # ===============================\n",
    "    # Create directory to store features if it doesn't exist\n",
    "    output_dir = f'features/{layer_name}/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save train and test features and labels\n",
    "    torch.save(train_features, os.path.join(output_dir, 'train_features.pt'))\n",
    "    torch.save(train_labels, os.path.join(output_dir, 'train_labels.pt'))\n",
    "    torch.save(test_features, os.path.join(output_dir, 'test_features.pt'))\n",
    "    torch.save(test_labels, os.path.join(output_dir, 'test_labels.pt'))\n",
    "\n",
    "    # Optional: save as .npy files if needed\n",
    "    train_features_np = train_features.cpu().numpy()\n",
    "    train_labels_np = train_labels.cpu().numpy()\n",
    "    test_features_np = test_features.cpu().numpy()\n",
    "    test_labels_np = test_labels.cpu().numpy()\n",
    "\n",
    "    # Save as .npy files\n",
    "    np.save(os.path.join(output_dir, 'train_features.npy'), train_features_np)\n",
    "    np.save(os.path.join(output_dir, 'train_labels.npy'), train_labels_np)\n",
    "    np.save(os.path.join(output_dir, 'test_features.npy'), test_features_np)\n",
    "    np.save(os.path.join(output_dir, 'test_labels.npy'), test_labels_np)\n",
    "\n",
    "    print(f\"Features from '{layer_name}' saved in '{output_dir}'\")\n",
    "\n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = \"features[8]\"  # Specify a layer from Inception-v3, e.g., Mixed_7c\n",
    "\n",
    "# Call the function to extract features\n",
    "train_features, train_labels, test_features, test_labels = extract_features(\n",
    "    layer_name, train_loader, test_loader, model, device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
