{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Standard library\n",
    "# =========================\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# Core scientific stack\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================\n",
    "# PyTorch + TorchVision\n",
    "# =========================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models as tv_models\n",
    "\n",
    "# =========================\n",
    "# timm\n",
    "# =========================\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "\n",
    "# =========================\n",
    "# Metrics (scikit-learn)\n",
    "# =========================\n",
    "import sklearn.metrics as sk_metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    cohen_kappa_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     49\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Load the pre-trained Inception-v3 model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m model = \u001b[43mmodels\u001b[49m.inception_v3(pretrained=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Update the fully connected layer for the number of classes\u001b[39;00m\n\u001b[32m     55\u001b[39m model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
      "\u001b[31mNameError\u001b[39m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming y_true and y_pred are already defined\n",
    "def get_classes(data_dir):\n",
    "    \"\"\"Get class names from dataset directory.\"\"\"\n",
    "    all_data = datasets.ImageFolder(data_dir)\n",
    "    return all_data.classes\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size, train=False):\n",
    "    \"\"\"Prepare data loaders for training, validation, and testing.\"\"\"\n",
    "    if train:\n",
    "        # Data augmentation for training\n",
    "        transform = T.Compose([\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomVerticalFlip(),\n",
    "          \n",
    "            T.Resize((299, 299)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        train_data = datasets.ImageFolder(os.path.join(data_dir, \"train/\"), transform=transform)\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        return train_loader, len(train_data)\n",
    "    else:\n",
    "        # Validation and test data transformations\n",
    "        transform = T.Compose([\n",
    "            T.Resize((299, 299)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        val_data = datasets.ImageFolder(os.path.join(data_dir, \"validation/\"), transform=transform)\n",
    "        test_data = datasets.ImageFolder(os.path.join(data_dir, \"test/\"), transform=transform)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        return val_loader, test_loader, len(val_data), len(test_data)\n",
    "\n",
    "# Dataset paths and loaders\n",
    "dataset_path = \"new_directories\"\n",
    "batch_size = 32  # Update batch size for efficiency\n",
    "\n",
    "(train_loader, train_data_len) = get_data_loaders(dataset_path, batch_size, train=True)\n",
    "(val_loader, test_loader, valid_data_len, test_data_len) = get_data_loaders(dataset_path, batch_size, train=False)\n",
    "\n",
    "classes = get_classes(\"new_directories/train\")\n",
    "num_classes = len(classes)\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "dataset_sizes = {\"train\": train_data_len, \"val\": valid_data_len}\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the pre-trained Inception-v3 model\n",
    "model = models.inception_v3(pretrained=True)\n",
    "\n",
    "# Update the fully connected layer for the number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Send the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    \"\"\"Train and validate the model.\"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluation mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "                    # Handle auxiliary logits for Inception-v3\n",
    "                    if isinstance(outputs, tuple) or hasattr(outputs, \"logits\"):\n",
    "                        main_outputs = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n",
    "                        aux_outputs = outputs.aux_logits if hasattr(outputs, \"aux_logits\") else None\n",
    "                        loss = criterion(main_outputs, labels)\n",
    "                        if aux_outputs is not None:  # Add auxiliary loss if present\n",
    "                            loss += 0.4 * criterion(aux_outputs, labels)\n",
    "                    else:\n",
    "                        main_outputs = outputs\n",
    "                        loss = criterion(main_outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(main_outputs, 1)  # Extract predictions from logits\n",
    "\n",
    "                    # Backward pass and optimization in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # Step the scheduler in the training phase\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_true = []\n",
    "y_proba = []\n",
    "y_pred = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader):\n",
    "        # Forward pass\n",
    "        output = model(x.to(device))\n",
    "        \n",
    "        # Store true labels\n",
    "        y_true.extend(y.numpy())\n",
    "        \n",
    "        # Get predicted probabilities (softmax output)\n",
    "        probabilities = torch.softmax(output, dim=1)  # Assuming it's a multi-class classification\n",
    "        y_proba.extend(probabilities.cpu().numpy())  # Store probabilities\n",
    "        \n",
    "        # Get predicted classes (argmax for final class prediction)\n",
    "        pred = torch.argmax(probabilities, axis=1).cpu().numpy()\n",
    "        y_pred.extend(pred)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "\n",
    "# Plot the confusion matrix without percentages\n",
    "disp.plot(cmap=\"Blues\", values_format='')\n",
    "plt.title(\"Inception-v3\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=classes, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finaltrain = pd.DataFrame([])\n",
    "\n",
    "finaltrain = finaltrain._append({\n",
    "                                        'Accuracy' : round(accuracy_score(y_true, y_pred)*100,3),\n",
    "                                        'PrecisionTrain':round(precision_score(y_true, y_pred, average = 'weighted')*100,3),\n",
    "                                        'RecallTrain':round(recall_score(y_true, y_pred, average = 'weighted')*100,3)  ,\n",
    "                                        'F1Train':round(f1_score(y_true, y_pred, average = 'weighted')*100,3)}\n",
    "                                      \n",
    "                                        , ignore_index=True)\n",
    "finaltrain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "features = {}\n",
    "\n",
    "# Hook function to capture the output from any layer\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Function to register the hook based on layer name\n",
    "def register_layer_hook(model, layer_name):\n",
    "    # Use eval() to access the layer dynamically\n",
    "    layer = eval(f'model.{layer_name}')\n",
    "    layer.register_forward_hook(get_features(layer_name))\n",
    "\n",
    "# ===============================\n",
    "# 3. Extract Features from ResNet's Specified Layer\n",
    "# ===============================\n",
    "# Assume train_loader and test_loader are defined DataLoader objects for your dataset\n",
    "\n",
    "def extract_features(layer_name, train_loader, test_loader, model, device):\n",
    "    # Register hook for the provided layer name\n",
    "    register_layer_hook(model, layer_name)\n",
    "    \n",
    "    train_features_list = []  # To store features for training data\n",
    "    train_labels_list = []  # To store labels for training data\n",
    "    test_features_list = []  # To store features for test data\n",
    "    test_labels_list = []  # To store labels for test data\n",
    "\n",
    "    # Extract features from training dataset\n",
    "    for images, labels in train_loader:\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            _ = model(images)\n",
    "            \n",
    "            # Extract layer features\n",
    "            layer_features = features[layer_name]\n",
    "            \n",
    "            # Flatten features if needed (depends on the shape of your features)\n",
    "            layer_features = layer_features.view(layer_features.size(0), -1)\n",
    "            \n",
    "            train_features_list.append(layer_features)\n",
    "            train_labels_list.append(labels)\n",
    "\n",
    "    # Extract features from test dataset\n",
    "    for images, labels in test_loader:\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            _ = model(images)\n",
    "            \n",
    "            # Extract layer features\n",
    "            layer_features = features[layer_name]\n",
    "            \n",
    "            # Flatten features if needed\n",
    "            layer_features = layer_features.view(layer_features.size(0), -1)\n",
    "            \n",
    "            test_features_list.append(layer_features)\n",
    "            test_labels_list.append(labels)\n",
    "\n",
    "    # Concatenate features and labels from the list to create tensors\n",
    "    train_features = torch.cat(train_features_list)\n",
    "    train_labels = torch.cat(train_labels_list)\n",
    "    test_features = torch.cat(test_features_list)\n",
    "    test_labels = torch.cat(test_labels_list)\n",
    "\n",
    "    # ===============================\n",
    "    # 4. Save Features to Files\n",
    "    # ===============================\n",
    "    # Create directory to store features if it doesn't exist\n",
    "    output_dir = f'features/{layer_name}/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save train and test features and labels\n",
    "    torch.save(train_features, os.path.join(output_dir, 'train_features.pt'))\n",
    "    torch.save(train_labels, os.path.join(output_dir, 'train_labels.pt'))\n",
    "    torch.save(test_features, os.path.join(output_dir, 'test_features.pt'))\n",
    "    torch.save(test_labels, os.path.join(output_dir, 'test_labels.pt'))\n",
    "\n",
    "    # Optional: save as .npy files if needed\n",
    "    train_features_np = train_features.cpu().numpy()\n",
    "    train_labels_np = train_labels.cpu().numpy()\n",
    "    test_features_np = test_features.cpu().numpy()\n",
    "    test_labels_np = test_labels.cpu().numpy()\n",
    "\n",
    "    # Save as .npy files\n",
    "    np.save(os.path.join(output_dir, 'train_features.npy'), train_features_np)\n",
    "    np.save(os.path.join(output_dir, 'train_labels.npy'), train_labels_np)\n",
    "    np.save(os.path.join(output_dir, 'test_features.npy'), test_features_np)\n",
    "    np.save(os.path.join(output_dir, 'test_labels.npy'), test_labels_np)\n",
    "\n",
    "    print(f\"Features from '{layer_name}' saved in '{output_dir}'\")\n",
    "\n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = \"Mixed_7c\"  # Specify a layer from Inception-v3, e.g., Mixed_7c\n",
    "\n",
    "# Call the function to extract features\n",
    "train_features, train_labels, test_features, test_labels = extract_features(\n",
    "    layer_name, train_loader, test_loader, model, device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
